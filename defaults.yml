# ==========================================================================
# DEFAULTS
# Represents default configurations applied to all different component types
# Can be overridden as show in the config.example.yml
#
# NOTE: The settings in this file are not used or parsed, simply informative
# ==========================================================================
- &stat_reporter_defaults
  type: powerpool.reporters.StatReporter
  # Whether or not the reporter will call log_one_minute as user "pool" for all
  # shares submitted to allow pool tracking
  report_pool_stats: True
  # The worker that pool stats get reported as. Only applies with
  # reporter_pool_stats = True
  pool_worker: ""
 
- &redis_reporter_defaults  # Also has all the defaults of StatReporter!
  type: powerpool.reporters.RedisReporter

  # Shares can be submitted to redis on independent share "chains" to allow
  # cooperatively solving blocks between many payout types. Should be different
  # for each different payout type...
  chain: 1
 
  # Used directly to configured redis-py redis instance. Read redis py docs
  # for more information
  redis: {}

# The jobmanager is in charge of building jobs for the stratum workers,
# submitting blocks to rpc servers, and pushing new block notifications to
# clients
- &monitor_network_defaults
  type: powerpool.jobmanagers.MonitorNetwork

  # The difficulty to start people out when they connect. Will be the
  # fixed difficulty if vardiff is disabled
  start_difficulty: 1
  # a list of connections to daemons to get block templates from
  # and submit complete blocks to. Required
  coinservs: []

  # Short currency name used by the reporter as needed to properly report
  # block submissions. Required
  currency: 

  # Should the proof of work algorithm be used to produce the block hash, or
  # sha256. Most use sha256, but some like Darkcoin use the POW algo
  pow_block_hash: True

  # what algorithm should these jobs be hashed with? Passed to reporter on
  # submission for recording and checking compatible StratumServer. Required.
  algo: 

  # This should contain a list of keys for defined AuxNetworkMonitor Components
  merged: []

  # address that all blocks will be paid out to. Make sure this is right! Required.
  pool_address: 

  # should we poll the RPC server for new blocks? True will force polling,
  # null will poll if push notifications are disabled, and False will force
  # off
  poll:

  # the definition of a target of difficulty 1. 4 zeroes for scrypt, 8 for 
  # sha...
  diff1: 0x0000FFFF0000000000000000000000000000000000000000000000000000

  # The number of hashes a single diff1 share takes on average to compute
  # 0xFFFFFFFF for sha256 and dark diff, 0xFFFF for scrypt. Used for showing 
  # hashrate
  hashes_per_share: 0xFFFFFFFF

  # time between checking live rpc for new blocks... lower means less orphan
  # blocks... Unused if using push block signals
  block_poll: 2
  # block polls between generating a new job for workers (running gbt, etc)
  job_generate_int: 75
  # Time between pinging rpc_servers that are down
  rpc_ping_int: 2
  # Pay out Darkcoin masternodes if True. Blocks may be rejected if False
  payout_drk_mn: True
  # A blockheight at which to set profitability to 0. Usually used to indicate
  # the height at which a coin is going PoS. Default is None
  max_blockheight:

# The HTTP health monitor. Most configs go straight to Flask configuration
- &server_monitor_defaults
  type: powerpool.monitor.ServerMonitor

  # Show tracebacks for erroring views. Allow debug view to display (possibly
  # shows PASSWORDS!)
  DEBUG: false
  # Address to bind for accepting HTTP connections. Localhost by default
  address: 127.0.0.1
  port: 3855

# This defines default configurations that will be applied to every
# StratumServer configuration
- &stratum_server_defaults
  type: powerpool.stratum_server.StratumServer

  address: 0.0.0.0
  port: 3333

  # The difficulty to start people out when they connect. Will be the
  # fixed difficulty if vardiff is disabled
  start_difficulty: 128

  # what algorithm should these jobs be hashed with? Must be an algo
  # listed in the stratum manager dictionary. Required.
  algo: 

  # Configuration that each vardiff enabled interface will use
  vardiff:
      # whether our this port will be vardiff enabled
      enabled: False
      # the overal shares per minute we're targeting
      spm_target: 20
      # time between checks triggered from share submission in seconds
      interval: 10
      # the available difficulty tiers. Will adjust to one of these
      tiers:
          - 8
          - 16
          - 32
          - 64
          - 96
          - 128
          - 192
          - 256
          - 512
          
  # The minimum allowable user-settable difficulty. Vardiff may still
  # adjust lower/higher
  minimum_manual_diff: 64

  # time between sending latest job to workers when there is no new block
  push_job_interval: 30

  # the agent server allows data collection agents to connect and report
  # stats about stratum clients. disabled by default. If enabled an agent
  # server will be started to mirror every stratum port add `port_diff`
  # higher port number (ie stratum port 3333 will create agent port 4444 by
  # default)
  agent:
      enabled: False
      port_diff: 1111
      accepted_types:
          - temp
          - status
          - hashrate
          - thresholds

  # aliases allow you to automatically translate a friendly username to to a
  # predefined address. the donate address is similar, except that any invalid
  # address is translated to it
  aliases: {}

# General process management configurations
- &powerpool_defaults
  type: powerpool.main.PowerPool

  # The name of the powerpool process on the system. Useful for quickly
  # identifying pid with grep and ps
  procname: powerpool
  # Grace period before outright terminating the process after termination is
  # requested
  term_timeout: 10

  # Configures standard python loggers. type must be a logging handler provided
  # by python std lib
  loggers:
      - type: StreamHandler
        level: NOTSET

  # Can be overridden in any specific Component's logger with log_level attribute
  default_component_log_level: INFO
  
  # A list of modules and hashing algorithms that you'd like to attempt to
  # load on startup.
  algorithms:
        x11: drk_hash.getPoWHash
        scrypt: ltc_scrypt.getPoWHash
        scryptn: vtc_scrypt.getPoWHash
        sha256: cryptokit.sha256d
        blake256: blake_hash.getPoWHash
  
  # server side size extranonce size. synonymous with worker id internally, used
  # to give a unique extranonce to each connection
  extranonce_serv_size: 8
  # size that clients will generate in bytes
  extranonce_size: 4
